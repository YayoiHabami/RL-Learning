# なんか書いててなにがやりたいのかわからんくなってきた

とくにベイズの定理をこんなに長々と説明する必要あるか？

あとベイズの定理の部分とMAP推定の部分で確率変数（と実現値？）の記法にゆれがあるからどちらかに統一したい。

# MAP推定

MAP推定（Maximum a Posteriori estimation; 最大事後確率推定）をEMアルゴリズムにより行うことが可能です。

## ベイズの定理

### 概要：ベイズの定理

はじめにベイズ統計学やベイズ推論でよく使われるいくつかの語を記述します。ここで、 $X,Y$ を事象として定義し、簡単のため $Y$ を結果、 $X$ をその原因であると仮定します。

**事前確率**（*prior probability*） $P(X)$ は $X$ が起こる確率であり、結果 $Y$ に依存しない $X$ の起こる確率を示します。次に**事後確率**（*posterior probability*） $P(X|Y)$ は結果 $Y$ が生じた差異、その原因が $X$ である条件付き確率です。同様に条件付き確率 $P(Y|X)$ も考えられますが、「原因 $X$ が生じた際に結果 $Y$ が発生する確率」ではなく「結果 $Y$ が生じたとき、その原因が $X$ であることのもっともらしさ（尤もらしさ）」、すなわち**尤度**（*likelihood*）として一般に扱います。最後に、結果 $Y$ の確率 $P(Y)$ は**全確率**や**周辺尤度**と呼ばれますが、この詳細はのちに述べます。

さて、上記の確率（尤度）を用いると、**ベイズの定理**（*Bayes' theory*）が次のように定義できます。

$$P(X|Y)=\frac{P(Y|X)P(X)}{P(Y)}$$

この式は条件付き確率の定義 $P(X|Y)=\frac{P(X\cap Y)}{P(Y)}, P(Y|X)=\frac{P(X\cap Y)}{P(X)}$ から導出されます。

> ここで、ベイズの定理は**時間の流れに逆らった**確率の計算を行うための手法と考えることもできます[1]。上式の $X,Y$ をそれぞれ原因、結果として置き換えると
>
> $$\underbrace{P(原因|結果)}_{時間の流れと逆}=\frac{P(結果|原因)P(原因)}{P(結果)}$$
> 
> 右辺の $P(原因), P(結果)$ は時間の流れに関係のない計算で、また $P(結果|原因)$ も原因に基づく結果の確率ですので順方向の確率を計算しています。一方で左辺の $P(原因|結果)$ は「結果に基づく原因の確率」であり、ある種時間の流れに逆らっていると見ることもできます。ここから、ベイズの定理では時間の流れを逆転させる計算を行える、と考えることも可能ではないでしょうか。

さて先ほど省略した全確率（周辺尤度） $P(Y)$ ですが、 $X$ が原因、 $Y$ が結果という仮定のもとでは計算が大変です。というのも $P(Y)$ を考えるためには、すべての原因 $x$ について原因が $x$ であった場合の結果 $Y$ の生じる確率 $P(Y|X=x)P(X=x)$ を足し合わせる必要があるからです。たとえば原因 $X$ が取りうる事象が離散値であった場合、その値を $x_1,x_2,...,x_n$ とすれば全確率は次のように書くことができます。

$$P(Y)=\sum_{i=1}^n{P(Y|X=x_i)P(X=x_i)}$$

ここで、右辺では左辺にあった原因 $X$ が消えてなくなりました。このように事象（変数）の確率の和（積分）をとることを**周辺化**というため、全確率は**周辺尤度**（*marginal likelihood*）とも呼ばれます。

### 連続型確率分布への拡張

上に述べたベイズの定理では離散値の事象を対象として考えましたが、後のためには連続型の確率分布を考える必要があります。結果 $y$ のための統計モデルを考え、そのパラメタを $\theta$ とします。このとき、上に述べた4つの確率は次のように言い換えることができます。

- 事前確率 $f(\theta)$ 　: 標本 $y$ を得る前のパラメタ $\theta$ の確率分布
- 事後確率 $f(\theta|y)$  : 標本 $y$ を得たあとのパラメタ $\theta$ の確率分布
- 尤度 $f(y|\theta)$ 　　: パラメタ $\theta$ を定めたもとで標本 $y$ が得られる確率
- 周辺尤度 $f(y)$ 　: 標本 $y$ が得られる確率

確率密度関数 $f$ を用いて、ベイズの定理は

$$f(\theta|y)=\frac{f(y|\theta)f(\theta)}{f(y)}\left(=\frac{\mathcal{L}(\theta;y)f(\theta)}{f(y)}\right)$$

と書けます。ここで $f(y|\theta)$ は尤度ですので、 $\mathcal{L}(\theta;y)$ とも置き換え可能です。また、このとき周辺尤度 $f(y)$ は次のように計算されます。

$$f(y)=\int_{-\infty}^\infty{f(y|\theta)f(\theta)d\theta}$$

このように周辺尤度 $f(y)$ はその計算が大変なので、ベイズの定理を次のようにして用いることも多いです。

$$f(\theta|y)\propto f(y|\theta)f(\theta)$$

## MAP推定

### ベイズ推論

最尤推定ではパラメタ $\theta$ を決定論的な変数として扱いました。これを確率変数として扱いたい場合もあると思います。この場合に用いられるのが**ベイズ推論**（*Bayesian inference*）です。

パラメタ $\theta$ を確率変数として扱うことにしたので、以下ではその分布を考えることになります。標本 $\pmb{X}=X_1,...,X_n$ が与えられたとき、事前確率 $p(\theta)$ 、尤度 $p(\pmb{X}|\pmb{\theta})$ 、事後確率 $p(\theta|\pmb{X})$ などが定義できます。

パラメトリックモデルでは確率変数 $X$ とパラメタ $\theta$ を区別し $g(X;\theta)$ と記述しました。ベイズ推論ではいずれも確率変数ですので、モデルを条件付き確率とみなして $g(X|\theta)$ と表記します。ベイズ推論では、事後確率 $p(\theta|\pmb{X})$ に関してパラメトリックモデル $g(X|\theta)$ を平均化した分布である**事後確率分布**（*posterior predictive distribution*）を利用します。

$$\hat{f}(X)=\int{g(X|\theta)p(\theta|\pmb{X})}$$

事後確率分布 $\hat{f}(X)$ は、標本 $\pmb{X}$ の背後にある確率質量関数/確率密度関数 $f(X)$ の推定値です。また、ベイズの定理と尤度の定義（ $p(\pmb{X}|\theta)=\prod_{i=1}^n{g(X_i|\theta)}$ ）を用いれば、事後確率分布 $\hat{f}(X)$ は次のように求まります。

$$\hat{f}(X)=\frac{\int{g(X|\theta)\prod_{i=1}^n{g(X_i|\theta)}p(\theta)d\theta}}{\int{\prod_{i=1}^n{g(X_i|\theta)}p(\theta')d\theta'}}\tag{12}$$

すなわち、ベイズ推論の枠組みにおいては事前確率 $p(\theta)$ とパラメトリックモデル $g(X|\theta)$ さえ定めれば確率分布を推定することができます（特別な推定や最適化が不必要）。

### MAP推定

パラメタ $\theta$ の次元数が高い場合、式 $(12)$ に含まれる $\theta,\theta'$ の積分を行うのは大変です。ここで、パラメトリックモデル $g(X|\theta)$ の平均化ではなく、事後確率 $p(\theta|\pmb{X})$ を最大にする値（**最頻値**）のみを用いて近似することを考えます。最頻値を $\hat\theta_{MAP}$ とするとき、推定値は

$$\hat{f}(X)=g(X; \hat\theta_{MAP})$$

と書けます。この式により推定を行う手法を**最大事後確率推定**（*maximum a posteriori estimation*; MAP推定）といいます[2]。ここで、最頻値 $\hat\theta_{MAP}$ は

$$\begin{aligned}\hat\theta_{MAP}=&\argmax_\theta{p(\theta|\pmb{X})}\\
=&\argmax_\theta{[\log{p(\pmb{X}|\theta)+\log{p(\theta)}}]}\end{aligned}$$

と書けます。最尤推定法では第一項の対数尤度 $\log{p(\pmb{X}|\theta)}$ のみを最大化しました。MAP推定ではこれに加えて対数事前確率 $p(\theta)$ も最大化しますが、これにより最尤推定解が事前確率の大きいほうに補正されます。

> *maximum a posteriori* の意味
>
> *a posteriori* は「より後のものから」を意味するラテン語です。条件付き確率の一種である事後確率はその英名を *posterior probability* ということから、 *maximum a posteriori* は単純に最大の事後確率であることがわかります。

### EMアルゴリズムによるMAP推定

復習になりますが、 $t$ 回目のステップで得られる推定値を $\theta^{(t)}$ （初期値は $\theta^{(0)}$ ）とすれば、EMアルゴリズムは次のように表せます。

> **E-step**：Q関数の計算<br>　 $y$ と $\theta^{(t)}$ のもとで $Q(\theta|\theta^{(t)})$ を計算
>
> **M-step**：上を $\theta$ について最大化<br>　 $\forall \theta\in\Omega_\theta$ に対し $Q(\theta^{(t+1)}|\theta^{(t)})\geq Q(\theta|\theta^{(t)})$ となる $\theta^{(t+1)}$ を算出
>
> $$\theta^{(t+1)}=\argmax_{\theta\in\Omega_\theta}Q(\theta|\theta^{(t)})$$

ここで、Q関数は次の式で定義される、事後分布 $\ell_c(\theta')=\ln f(x|\theta')$ による対数尤度の期待値でした。

$$Q(\theta|\theta')=\mathbb{E}\left[\ell_c(\theta')|y,\theta\right]=\int_{\Omega_Z}{\ell_c(\theta')f(z|y,\theta)dz}$$

上に述べたように最頻値


 
## 参考文献

[1] 入門統計学 第2版, 栗原伸一, オーム社, 第1刷

[2] 機械学習のための確率と統計, 杉山将, 講談社, 第1刷

[3] [EMアルゴリズム徹底解説（おまけ）〜MAP推定の場合〜](https://qiita.com/kenmatsu4/items/d797bf6250eee5048865)